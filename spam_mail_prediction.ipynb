{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abdülhalim YAYDEMİR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a2cd1",
   "metadata": {},
   "source": [
    "### Eğitim verilerinden priors ve likelihoods bulma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc07518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors:\n",
      "P_spam =  0.28983833718244806\n",
      "P_ham =  0.710161662817552\n",
      "Likelihoods: \n",
      "P_x_spam =  [0.08665339 0.07669323 0.00298805 ... 0.00099602 0.00099602 0.00099602]\n",
      "P_x_ham =  [0.17113821 0.20772358 0.00081301 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Kütüphaneler \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# verileri eğitim ve test olarak ayırmak için kullanıldı.\n",
    "# metinleri vektör yapmak için kullanıldı.\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "\n",
    "# En son karşılaştırma amaçlı kullanıldı.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Dosya okuma ve düzenleme\n",
    "df = pd.read_csv('spam.csv',encoding='ISO-8859-1')\n",
    "veri = df.copy()\n",
    "veri = veri.drop([\"Unnamed: 0\"], axis=1)\n",
    "veri = veri.rename(columns={\"label\":\"etiket\",\"text\":\"metin\",\"label_num\":\"etiket_num\"})\n",
    "\n",
    "\n",
    "# Metin içeriği düzenleme (küçük harfe çevirme)\n",
    "tumcumleler = []\n",
    "for i in range(len(veri[\"metin\"].values)):\n",
    "    r1 = veri[\"metin\"].values[i]    \n",
    "    temizcumle = []\n",
    "    cumleler = r1.lower()\n",
    "    \n",
    "    for kelimeler in cumleler.split():\n",
    "        temizcumle.append(kelimeler)\n",
    "        \n",
    "    tumcumleler.append(\" \".join(temizcumle))\n",
    "\n",
    "veri[\"yeni_metin\"] = tumcumleler\n",
    "\n",
    "\n",
    "\n",
    "# vektör oluşturma\n",
    "cv = CountVectorizer()\n",
    "cv.fit(veri[\"yeni_metin\"])\n",
    "x = cv.fit_transform(veri[\"yeni_metin\"]).toarray()\n",
    "y = veri[\"etiket_num\"]\n",
    "\n",
    "\n",
    "\n",
    "# eğitim ve test verileri olarak ayırma\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.33)\n",
    "\n",
    "\n",
    "\n",
    "# Eğitim verilerinden Prior'lar hesaplama \n",
    "spam_count = 0.0\n",
    "for i in range(np.shape(y_train)[0]):\n",
    "    if y_train.values[i]==1:\n",
    "        spam_count=spam_count+1.0\n",
    "        \n",
    "ham_count=(np.shape(y_train)[0])-spam_count\n",
    "\n",
    "P_spam = spam_count/(np.shape(y_train)[0])\n",
    "P_ham = ham_count/(np.shape(y_train)[0])\n",
    "\n",
    "print(\"Priors:\")\n",
    "print(\"P_spam = \",P_spam)\n",
    "print(\"P_ham = \",P_ham)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Eğitim verilerinden Likelihood'lar hesaplandı\n",
    "P_x_spam = np.arange(np.shape(x_train)[1])\n",
    "P_x_ham = np.arange(np.shape(x_train)[1])\n",
    "for j in range(np.shape(x_train)[1]):\n",
    "    x_spam_count = 0.0\n",
    "    x_ham_count = 0.0\n",
    "    for i in range(np.shape(x_train)[0]):\n",
    "        if (x_train[i][j]!=0) & (y_train.values[i]==1):\n",
    "            x_spam_count = x_spam_count + 1.0\n",
    "        if (x_train[i][j]!=0) & (y_train.values[i]==0):\n",
    "            x_ham_count = x_ham_count + 1.0\n",
    "    P_x_spam[j] = x_spam_count\n",
    "    P_x_ham[j] = x_ham_count\n",
    "    \n",
    "P_x_spam = P_x_spam/spam_count\n",
    "P_x_ham = P_x_ham/ham_count \n",
    "\n",
    "print(\"Likelihoods: \")\n",
    "print(\"P_x_spam = \",P_x_spam)\n",
    "print(\"P_x_ham = \",P_x_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e946fa6",
   "metadata": {},
   "source": [
    "### Test metinlerinin etiketlerini tahmin etme, doğruluk hesabı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ae69b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6438195664909198\n"
     ]
    }
   ],
   "source": [
    "# Test metin verileri için etiket verileri tahmin edildi.\n",
    "y_predict = np.arange(np.shape(x_test)[0])\n",
    "for i in range(np.shape(x_test)[0]):\n",
    "    NaiveBayes_spam = 1.0\n",
    "    NaiveBayes_ham = 1.0\n",
    "    for j in range(np.shape(x_test)[1]):\n",
    "        if (x_test[i][j]!=0):\n",
    "            NaiveBayes_spam = NaiveBayes_spam * P_x_spam[j]\n",
    "            NaiveBayes_ham = NaiveBayes_ham * P_x_ham[j]\n",
    "            \n",
    "    NaiveBayes_spam = NaiveBayes_spam * P_spam\n",
    "    NaiveBayes_ham = NaiveBayes_ham * P_ham\n",
    "    if (NaiveBayes_spam>=NaiveBayes_ham):\n",
    "        y_predict[i] = 1\n",
    "    if (NaiveBayes_spam<NaiveBayes_ham):\n",
    "        y_predict[i] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "# Tahmin etiket verileri ile test etiket verileri kıyaslandı\n",
    "predict_correct = 0.0\n",
    "predict_wrong = 0.0\n",
    "for i in range(np.shape(x_test)[0]):\n",
    "    if (y_predict[i] == y_test.values[i]):\n",
    "        predict_correct = predict_correct + 1.0\n",
    "    if (y_predict[i] != y_test.values[i]):\n",
    "        predict_wrong = predict_wrong + 1.0\n",
    "        \n",
    "        \n",
    "        \n",
    "# Doğruluk hesabı yapıldı\n",
    "accuracy = predict_correct/(predict_correct+predict_wrong)\n",
    "print(\"Accuracy = \",accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13380c3f",
   "metadata": {},
   "source": [
    "### Sklearn ile doğruluk hesabı "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c572e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_NB =  0.9818394844756884\n"
     ]
    }
   ],
   "source": [
    "# Sklearn kütüphanesi ile karşılaştırma yapıldı\n",
    "model=MultinomialNB()\n",
    "model.fit(x_train,y_train)\n",
    "tahmin=model.predict(x_test)\n",
    "accuracy_NB=accuracy_score(y_test,tahmin)\n",
    "print(\"Accuracy_NB = \",accuracy_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86193444",
   "metadata": {},
   "source": [
    "#### Sonuç \n",
    "#### Naive Bayes manuel olarak uygulandığında % 64 doğruluk bulunmuşken, aynı veri Sklearn tarafından % 98 bulunmuştur.\n",
    "#### Bu değer veri setinin ön işlem sürecini iyileştirerek (noktalama işaretleri,sayılar, tekrar sayısı, gereksiz sözçükler) \n",
    "#### ve farklı bir vektör oluşturma yöntemi ile iyileştirilebilir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
